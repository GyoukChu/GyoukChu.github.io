---
layout: single
title:  "[DCASE Task 2] 연도 별 차이 정리"
categories: dcase_task2
tag: [dcase_task2]
toc: true
author_profile: false
---

# 2020
**Unsupervised Detection of Anomalous Sounds for Machine Condition Monitoring**

[DCASE2020 Task 2 Baseline Repo](https://github.com/y-kawagu/dcase2020_task2_baseline)

## Terminology
Machine Type: 말 그대로 머신 종류, 다음 6개 중 하나: ToyCar, ToyConveyor, fan, pump, valve, and slider (slide rail)

Machine ID: 같은 Machine Type에서 identifier. ToyCar는 id 01~07, ToyConveyor는 id 01~06, 나머지는 id 00~06으로 이루어져 있다.

## Dataset
![2020_1]({{site.url}}/images/2023-03-14-dcase_task2/2020_1.png)
Development Dataset: Machine Type마다 training dataset은 약 1000개 (모두 정상), test dataset은 약 (100~200)x2개 (정상,비정상). ToyCar 같은 경우 id 01~04 까지의 데이터만 포함되어 있는 등 id의 일부로 구성되어 있다.

Additional Training Dataset: Evaluation dataset에서 사용할 Machine Id가 포함되어 있는 추가 training data이다. Machine Type마다 약 1000개의 training dataset (모두 정상)

Evaluation Dataset: Machine Type마다 약 400개의 Unlabeled dataset. Machine ID는 development dataset에 있던 것과는 다르고, additional training dataset에 있던 것과 동일하다.

## Evaluation & Ranking
기본적으로 모든 Machine Type 별 Machine ID 마다, data file 하나당 anomaly score를 제시해야 된다. 그래서 최종 랭킹은 4가지 단계로 되어 있는데,

1. 각각의 Machine ID 별 AUC와 pAUC(p=0.1)을 계산한다.
2. 각 Machine Type에 대해 AUC와 pAUC를 평균낸다.
3. 각 Machine Type에 대해 랭킹을 매긴다.
4. 랭킹의 평균의 순위가 최종 랭킹이다.

## Results
[DCASE2020 Task 2 Rank](https://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds-results)

[DCASE2020 Task 2 Winner](https://dcase.community/documents/challenge2020/technical_reports/DCASE2020_Giri_103_t2.pdf)

1등 팀의 모델만 살펴보자면, Group Masked Autoencoder for Distribution Estimation (Group MADE) 와 MobileNetV2 앙상블 모델이 1등을 했다. Group MADE는 2개의 과거 time frame과 2개의 미래 time frame으로 현재 시점을 reconstruction하는 reconstruction task고, MobileNetV2를 이용한 Machine ID classification task도 수행했다. 앙상블은 각각의 model에 대해서 Machine ID 마다 표준화(mean=0,var=1)하고 mean or max ensembling 했다는데 ~~둘 중 뭘 한거야~~

# 2021
**Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions**

[DCASE2021 Task 2 AE-Baseline Repo](https://github.com/y-kawagu/dcase2021_task2_baseline_ae)

[DCASE2021 Task 2 MobileNetV2-Baseline Repo](https://github.com/y-kawagu/dcase2021_task2_baseline_mobile_net_v2)

## Difference
Domain Shift 조건이 추가되었다. 즉, training data와 test data의 acoustic characteristic이 바뀌었다. Acoustic characteristic이라 하면 작동 속도(operating speed), 노이즈(environmental noise), machine load(예를 들면 ToyConveyor 위에 물체 무게 뭐 이런 걸 얘기하는 것 같다) 등등.

Training과 Testing 시 Dataset이 같은 recording condition이었던 이상적인 경우인 2020년도의 task2와 다르게, 현실은 그런 operating condition이 다를 수 있기에 (얘를 들면 생산 라인에서 수요가 많으면 제품 무게나 작동 속도를 증가시켜야 되니까) 좀 더 현실적이다. 뭐 이렇게 얘기 하고 있다.

## Terminology
Machine Type: 말 그대로 머신 종류, 다음 7개 중 하나: ToyCar, ToyTrain, fan, pump, slider, valve, and gearbox (2020년과 다르게 gearbox가 추가되었다)

Section: 특정 Machine Type에서 2개의 domain으로 부터 온 데이터들. 즉, data의 subset이다. 2020년에서의 Machine ID와 유사한 듯 다른데, 2020년에는 machine ID와 product 간 1-1 correspondence가 있었다면 이번 2021년에는 section과 product 간 1-1 correspondence는 없다. 다시 말해 같은 product가 다른 section에 있을 수도 있고 다른 product가 같은 section에 있을 수도 있다. (아래 그림을 보니까 한 방에 이해가 된다)

Source Domain: Original Condition. 충분히 많은 Training data가 수집 된 그 조건이다.

Target Domain: Shifted Condition. 매우 적은 수의 training data가 수집 되어 있다. operating speed, machine load, viscoity(점성), heating temperature, environmental noise, SNR 등이 바뀌어 있다.

## Dataset
![2021_1]({{site.url}}/images/2023-03-14-dcase_task2/2021_1.png)
Development Dataset: 각 Machine Type에 대해 section 3개가 주어져 있다. Source Domain에서 약 1000개의 정상 데이터 및 Target Domain에서 약 3개의 정상 데이터가 Training Dataset이다. 그리고 Source Domain에서 약 100 x2개의 정상/비정상 데이터 및 Target Domain에서 약 100 x2개의 정상/비정상 데이터가 Test Dataset이다.

Additional Training Dataset: Evaluation dataset에서 사용할 Section이 포함되어 있는 추가 training data이다. 마찬가지로 Source Domain에서 약 1000개의 정상 데이터 및 Target Domain에서 약 3개의 정상 데이터로 training dataset이 구성되어 있다.

Evaluation Dataset: Source Domain에서의 data와 Target Domain에서의 data 모두 unlabeled 상태로 주어져있다. Section은 development dataset에 있던 것과는 다르고, additional training dataset에 있던 것과 동일하다.

특이사항으로는 Source Domain과 Target Domain간 data imbalance가 매우 심하다.

## Evaluation & Ranking
2020년과 동일한데, 최종 랭킹 방식이 바뀌었다. 기존의 4단계 대신, 전체 Machine Type, 전체 Section에 대해서 AUC, pAUC 들의 harmonic mean value를 Official score로 정하고 랭킹을 매겼다.

## Results
[DCASE2021 Task 2 Rank](https://dcase.community/challenge2021/task-unsupervised-detection-of-anomalous-sounds-results)

[DCASE2021 Task 2 Winner](https://dcase.community/documents/challenge2021/technical_reports/DCASE2021_Lopez_6_t2.pdf)

1등 팀의 모델만 살펴보자면, well-known domain adaptation technique을 쓰는 것 보다 그냥 여러 anomaly detector를 섞는 게 결과가 더 좋아서 2개의 self-supervised classifier(XVector1D, WaveNet)와 unsupervised reconstruction model인 NF-CDEE를 썼다. 특이한 점이라면 classification이 Machine ID가 없어서 Section으로 했는데 성능이 괜찮게 나온 거?

# 2022
**Unsupervised Anomalous Sound Detection for Machine Condition Monitoring Applying Domain Generalization Techniques**

[DCASE2022 Task 2 AE-Baseline Repo](https://github.com/Kota-Dohi/dcase2022_task2_baseline_ae)

[DCASE2022 Task 2 MobileNetV2-Baseline Repo](https://github.com/Kota-Dohi/dcase2022_task2_baseline_mobile_net_v2)

## Difference
Domain Generalization이 추가되었다. 큰 틀은 21년도와 동일한 데, test data에서 source domain인지 target domain인지 정보가 주어져있지 않아서 domain과 관계없이 같은 threshold로 anomaly를 detect 해야 하게 되었다. 마찬가지로 좀 더 일반적인 상황을 가정한 것이라 볼 수 있겠다.

## Dataset
![2022_1]({{site.url}}/images/2023-03-14-dcase_task2/2022_1.png)
21년도와 동일해서 Skip. Data 개수가 조금 씩 다르고, 앞서 말한 test data에서 domain 정보가 주어져있지 않다.

## Evaluation & Ranking
21년도와 동일한 방식.

## Results
[DCASE2022 Task 2 Rank](https://dcase.community/challenge2022/task-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results)

[DCASE2022 Task 2 Winner](https://dcase.community/documents/challenge2022/technical_reports/DCASE2022_Liu_8_t2.pdf)

1등 팀의 모델만 살펴보자면, Classifcation task를 수행함에 있어 우선 machine type, machine ID 모두 분류하는 (총 7x3=21개의 class) 모델을 pre-train하고, 그 다음 각 machine type에 대해 ID를 분류하는 (총 3개의 class) 모델으로 fine-tuning을 하였다. Anomaly Score를 선정함에 있어 Mahalanobis distance를 쓸지, probability 그대로 쓸지 등등 이것저것 해보고 제일 좋은 걸로 machine type마다 채택했다고 되어있고, Domain generatlization technique은 전혀 적용하지 않았다고 한다.

# 2023
**First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring**

[DCASE2023 Task 2 AE-Baseline Repo](https://github.com/nttcslab/dcase2023_task2_baseline_ae)

## Difference

첫 번째로, training data와 test data간 machine type이 전혀 다르다. 좀 더 골치 아픈 점은 training data의 machine은 10초 데이터인데, additional training data로 주어진 test data의 machine는 6초~18초 사이 데이터라 padding or ignoring 둘 중 하나 채택을 하거나 또 다른 방법을 적용해야 한다. 두 번째로, Section이 하나 뿐이다. 분류 모델이 계속 top이라서 이렇게 구성한건가 싶은 개인적인 생각.

개인적으로 의문이 드는 건 First-shot인데 additional training data로 test data의 machine data를 주면, 그냥 (training data + additional training data)로 pre-training 하고 additional training data로 fine-tuning 하면 되는데 이걸 왜 First-shot이라고 부르는지 모르겠다. test data에 있는 machine type에 대한 정보가 아예 없어야 되는거 아닌가?

## Dataset
![2023_1]({{site.url}}/images/2023-03-14-dcase_task2/2023_1.png)
데이터 개수는 22년도와 동일하고, Section이 단 하나, 그리고 machine type이 development dataset과 evaluation dataset에서 다른 것을 확인할 수 있다.

## Evaluation & Ranking
21/22년도와 동일한 방식.

## Results
[DCASE2023 Task 2 Rank](https://dcase.community/challenge2023/task-first-shot-unsupervised-anomalous-sound-detection-for-machine-condition-monitoring-results)

[DCASE2023 Task 2 Winner](https://dcase.community/documents/challenge2023/technical_reports/DCASE2023_Jie_64_t2.pdf)

1등 팀의 모델만 살펴보자면, Multi-Dimensional Attention Module (Axial Transformers 논문에서 제시한 걸 말하는건지 뭔지 그냥 Squeeze-excitation 같은 거 잘 안 되서 이거 썼다는데, 아무런 설명이 없다.)을 ResNet에 붙여 또 classification model을 학습했다. Class는 데이터 파일 이름에 있는 description 기준으로 나누었다고 한다. Metadata를 써서 최대한의 supervision을 주는 건 잘한 것 같다.