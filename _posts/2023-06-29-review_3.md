---
layout: single
title:  "[Review] SDE"
categories: review
tag: [review, SDE, Generative Model]
author_profile: false
---

앞서 Review한 Diffusion Model과, score-based model을 모두 통합하는 generalized framework를 제시한, SDE 논문을 최종적으로 리뷰하기 위해 몇 개의 논문을 살펴보자.

1. Estimation of Non-Normalized Statistical Models by Score Matching
2. A Connection Between Score Matching and Denoising Autoencoders
3. Generative Modeling by Estimating Gradients of the Data Distribution (NCSN)
4. Improved Techniques for Training Score-Based Generative Models (NCSNv2)
5. Score-Based Generative Modeling through Stochastic Differential Equations (SDE)

# 0. Introduction

## Stochastic Gradient Langevin Dynamics (SGLD)

딥러닝 학습에 있어서 parameter update하는 것을 생각해보자. $X$라는 N개 dataset이 주어져있을 때, 우리의 궁극적인 목표는 실제 데이터의 분포 $p_{X}(.)$를 model parameter $\theta$를 통해 $p(\theta \mid X)$, 다시 말해 X가 주어졌을 때 그 분포, pdf를 학습하는 것이다. $p(\theta \mid X) \propto p(\theta)\prod_{i=1}^{N}p(x_{i}\mid \theta)$ 이기에 optimization은 $argmax \; p(\theta)\prod_{i=1}^{N}p(x_{i}\mid \theta)$, MAP(Maximum a posteriori)를 찾으면 되는 것이다.

잘 알려져있는, 모두가 쓰는 방법은 Gradient Descent(GD), 특히 Stochastic Gradient Descent(SGD) 방법으로 전체 dataset X의 subset(=minibatch)에 대해서 $\Delta \theta_{t}=\frac{\epsilon_{t}}{2}(\nabla_{\theta_{t}}log p(\theta_{t})+\frac{N}{n}\sum_{i=1}^{n}\nabla_{\theta_{t}}log p(x_{i,t}\mid \theta_{t}))$로 파라미터을 업데이트한다. $\epsilon_{t}$는 step size, decreasing 하고 summation이 무한대이며 energy(square sum)는 finite한 조건이 붙어야 수렴한다.

여기서 SGLD의 논문에서는, 이런 SGD 방식이 parameter uncertainty를 놓쳐서 overfitting의 가능성이 있기에 이런 uncertainty를 capture하기 위한 Bayesian approach로 Markov chain Monte Carlo(MCMC) tech., 그 중에서도 Langevin dynamics를 소개하고 있다. gradient step 뿐만 아니라 Gaussian noise를 parameter update 시에 추가해주는 것. SGLD는 이런 Langevin Dynamics를 SGD와 합쳐서 업데이트 하는 방식을 제안했다. 즉, $\Delta \theta_{t}=\frac{\epsilon_{t}}{2}(\nabla_{\theta_{t}}log p(\theta_{t})+\frac{N}{n}\sum_{i=1}^{n}\nabla_{\theta_{t}}log p(x_{i,t}\mid \theta_{t}))+\epsilon_{t}\eta_{t} \quad where \; \eta_{t}\sim N(0,I)$. $\Delta \theta_{t} \sim N(\frac{\epsilon_{t}}{2}(\nabla_{\theta_{t}}log p(\theta_{t})+\frac{N}{n}\sum_{i=1}^{n}\nabla_{\theta_{t}}log p(x_{i,t}\mid \theta_{t})), \epsilon_{t}I)$와 같은 말이다.

잠시 DDPM으로 돌아가보자면, DDPM의 Abstract에 보면 이런 문장이 나온다.
>desinged according to a novel connection between diffusion probabilistic models and denoising score matching with "LANGEVIN DYNAMICS"

denoising score matching은 아래에서 다루고, 여기서 말하는 Langevin dynamics가 결국 forward processing에 있어 $x_{t}=\sqrt{1-\beta_{t}}x_{t-1}+\sqrt{\beta_{t}}\varepsilon$ 했던, 좀 더 정확히는 $+\sqrt{\beta_{t}}\varepsilon$ 했던 행동이 바로 Langevin MCMC를 적용한 것이라 볼 수 있다.

## Energy-Based Model

Energy function을 통해 pdf를 정의하고, 이를 통해 실제 데이터의 분포를 예측하고자 했던 모델이다. 다시 말해 energy function을 학습하는 것을 목표로 하는 모델. $X$라는 N개 dataset이 주어져있을 때, Energy function을 $\epsilon_{\theta}(x)$로 정의한다면 이것을 가지고 Boltzmann distribution을 통해 pdf를 정의할 수 있다: $p_{\theta}(x)=\frac{exp(-\epsilon_{\theta}(x))}{Z(\theta)}$. 이 때 $Z(\theta)=\int exp(-\epsilon_{\theta}(x))dx$는 normalizing coefficient. 이 논문에서도 파라미터를 업데이트함에 있어 SGLD를 사용하는데, $\nabla_{\theta_{t}}log \;p_{\theta_{t}}(x)=\nabla_{\theta_{t}}\epsilon_{\theta_{t}}(x)-\nabla_{\theta_{t}}log\;Z(\theta_{t})$로 정리된다.

# 1. Score-Matching

## Energy-Based Model의 문제점

간략히 소개한 EBM의 문제점에 대해 크게 2가지 정도로 설명하고 있다.

1. 적분 형태로 주어지는 $Z_{\theta}$는 analytically intractable한 경우가 대다수이다. 즉, 학습 시에 $-\nabla_{\theta_{t}}log\;Z(\theta_{t})$는 analytically & numerically 계산 불가능하다.
2. $\nabla_{\theta_{t}}\epsilon_{\theta_{t}}(x)$는 모델을 학습시키는거라 pytorch가 알아서 해줄건데, $-\nabla_{\theta_{t}}log\;Z(\theta_{t})$는 어떻게 되는가. EBM의 논문에서 이를 정리하면 $\nabla_{\theta_{t}}log\;Z(\theta_{t})=E_{x \sim p_{\theta_{t}}(x)} [ -\nabla_{\theta_{t}}\epsilon_{\theta_{t}}(x)]$가 된다고 적혀있다. 이걸 자세히 보면, $p_{\theta_{t}}(x)$에서 sampling을 해야 되는데, 이 자체가 오래 걸릴 뿐더러 학습한 모델에서 또 추가적인 연산이 필요하다. 본 논문에서는 "Estimation of non-normalized models is approached by MCMC methods, which are VERY SLOW, or by making some approximations, which may be quite poor"라고 말하고 있다.

## 개선점
Main idea는 "$p_{\theta}(x)$가 아닌 $s_{\theta}(x):= \nabla_{x} log\; p_{\theta}(x)$, 즉 그냥 density가 아닌 gradient of log-density"이다. score function이라고 말하는 것도 gradient of log-density이다. 이렇게 했을 때의 장점은, $\nabla_{x} log\;p_{\theta}(x)=-\nabla_{x}\epsilon_{\theta}(x)$로, $Z(\theta)$에 대한 걱정이 사라진다는 점.

그랬을 때 model의 목표는 단순 regression task 처럼 model score function과 실제 data의 score function간의 distance를 최소화 하는 것이다. 다시 말해, $$J(\theta)=\frac{1}{2} \int p_{data}(x)\|s_{\theta}(x)-\nabla_{x}log \; p_{data}(x)\|_{2}^2dx \\ =\frac{1}{2}E_{p_{data}}[\|s_{\theta}(x)-\nabla_{x}log \; p_{data}(x)\|_{2}^2]$$ 가 되겠다.
따라서 이를 최소화하는 $argmin \; J(\theta)$가 우리의 최종 파라미터가 되겠다.
논문에서 Theorem 1으로, 해당 objective는 $$J(\theta)=\frac{1}{2}\int p_{data}(x) [ tr(\nabla_{x}s_{\theta}(x))+\frac{1}{2}\|s_{\theta}(x)\|_{2}^{2} ]dx \;+\;const \\ = \frac{1}{2}E_{p_{data}}[tr(\nabla_{x}s_{\theta}(x))+\frac{1}{2}\| s_{\theta}(x)\|_{2}^{2}]\;+\;const' \\ \approx \frac{1}{N}\sum_{i=1}^{N} [ tr(\nabla_{x_{i}}s_{\theta}(x_{i}))+\frac{1}{2}\|s_{\theta}(x_{i})\|_{2}^{2} ] \;+\;const''$$로 계산할 수 있으며, Theorem 2 및 Corollary 3으로 SGLD를 쓰면 큰 수의 법칙에 의해 $\nabla J(\theta)=0$이 되는 우리의 목표인 파라미터로 업데이트가 적절히 이루어진다고 말하고 있다.

여기에 있어서 score function이 미분 가능하고, weak regularity 조건 (data distribution $p_{data}(x)$가 미분 가능하고, model score function과 실제 data score function의 square의 expectation이 유한하며, data의 분포와 model score의 분포의 곱이 어떠한 파라미터에 대해서라도 무한히 큰 값에 대해 0으로 수렴한다), 그리고 data distribution과 일치해지는 파라미터가 유일하게 존재하는 가정이 들어간다. 좋은 상황을 가정하자는 거다. 그렇지 않다면 typical한 SGD 처럼 global minima가 아닌 local minima에 빠질 수 있고, unexpected behavior를 보일 수 있기에.

## Example
논문의 Section 3.1에 Multivariate Gaussian Density를 예시로 앞서 말한 설명을 보여주고 있는데, 이걸 보니까 한 번에 확 와 닿았다. pdf로 Guassian density function, 파라미터 $\theta=\{M,\mu\}$일 때 $p_{M,\mu}(x)=\frac{1}{Z(M,\mu)}exp(-\frac{1}{2}(x-\mu)^{T}M(x-\mu))$로 ground-truth data pdf인 Guassian pdf를 유추한다고 가정해보자. 물론 이 경우에 한정해서는 $Z(\theta)$가 무엇인지 널리 알려져있지만, 모른다고 가정해보자. (애초에 실제 데이터가 어떤 분포를 따르는지 조차 모르는 경우가 대다수이며, $Z(\theta)$를 아는 경우는 현실에 거의 없다) 그렇다면 score function은 $s_{\theta}(x):= \nabla_{x} log\; p_{\theta}(x)=-M(x-\mu)$가 될 것이고, $tr(\nabla_{x}s_{\theta}(x))=-\sum m_{ii}$가 되기에, $J(\theta)=\frac{1}{N}\sum_{i=1}^{N}[-\sum m_{jj}+\frac{1}{2}(x_{i}-\mu)^{T}MM(x_{i}-\mu)]\;+\;const$가 된다. (N개의 data point $x_{i}$들, $M^{T}=M$은 당연) 따라서, $\nabla J(\theta)=0$이 되는 파라미터를 찾으면 되는데, $\nabla_{\mu} J(\theta)=MM\mu-MM\frac{1}{N}\sum x_{i}$ 라서 0이 되는 건 $\mu=\frac{1}{N}\sum_{i=1}^{N} x_{i}$가 되겠고, $\nabla_{M} J(\theta)=-I+M\frac{1}{2N}\sum_{i=1}^{N}(x_{i}-\mu)(x_{i}-\mu)^{T}+\frac{1}{2N}[\sum_{i=1}^{N}(x_{i}-\mu)(x_{i}-\mu)^{T}]M$ 이라서 0이 되는 건 $M^{-1}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\mu)(x_{i}-\mu)^{T}$가 되겠다. score matching 방식으로 찾은 평균과 분산이, Maximum likelihood Estimation 방법으로 찾은 평균/분산과 동일하다. 다시 생각해보면, 어떤 N개의 data가 있을 때 모집단의 평균은 당연히 sample average $\frac{1}{N}\sum_{i=1}^{N} x_{i}$ 로 추정할 것이고 분산은 당연히 sample covariance matrix $\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\mu)(x_{i}-\mu)^{T}$의 inverse로 추정하게 되는 그 직관과 동일하며 우리가 원하는 결과를 score matching 방식으로도 얻게 되는 것이다. ~~N이 크니까 모집단의 분산 N-1이나 N이나 뭐~~

## Summary
결국 기억해둬야 될 것은 gradient of log-likelihood를 score로 정의해서, model score $s_{\theta}(x):= \nabla_{x} log\; p_{\theta}(x)$와 data score $\nabla_{x} log\; p_{data}(x)$를 일치시키는 (L2 loss) 것이다.

# 2. Denoising Score-Matching

## 기존 Score-Matching의 문제점

Score Matching의 objective를 다시 보자:$$J(\theta)\approx \frac{1}{N}\sum_{i=1}^{N} [ tr(\nabla_{x_{i}}s_{\theta}(x_{i}))+\frac{1}{2}\|s_{\theta}(x_{i})\|_{2}^{2} ] \;+\;const$$ 여기서 $$\frac{1}{2}\| s_{\theta}(x)\|_{2}^{2}$$ 부분은, model을 통과한 $$s_{\theta}(x)$$로 부터 바로 구해질 수 있으나, $$tr(\nabla_{x}s_{\theta}(x))$$ 부분은, $$s_{\theta}(x)$$의 Jacobian matrix을 가지고 있어야 되기에 computational cost가 높다. 당연히 오래 걸리는 건 우리가 원하는 게 아니다.

본 논문에서 제시한 내용을 보기 전에, prerequisite으로 2가지 정도 알고 넘어가자.

## Parzen Window Density Estimation

우리가 input으로 주는 data는 어떤 식으로 분포되어 있는지 일반적으로는 전혀 알 수 없다. 정규 분포를 띈다? 그건 매우 운이 좋은 케이스라 볼 수 있겠다. 이럴 때 데이터의 분포, pdf를 추정하는 방법으로는 Kernel density estimation 혹은 KNN 등 여러가지 방법이 있지만 해당 논문에서 density estimator를 언급하고 있다.

pdf $p(x)$를 estimate하기 위해서, density라는 게 일정한 범위 내에서 데이터가 몇 개 있는가를 나타내기 때문에 $p(x)\approx \frac {k}{NV}$임을 이용한다. 이 때 V는 범위, N은 전체 데이터 수, k는 해당 범위에 속한 데이터 수를 뜻한다. KNN은 K를 고정했을 때 V를 결정하는 것이라 볼 수 있겠고, Kernel method는 V를 고정했을 때 K를 결정하는 방식이라 볼 수 있겠다. k를 결정하는 kernel function $K(u)$는 여러 가지가 있는데, Parzen Window는 이런 kernel function들 중 하나로, 길이 h의 hypercube가 있을 때 그 안에 속해있는 데이터 수를 세는 것이다. D dimension에서 $V=h^{D}$, $$k=\sum_{i=1}^{N}K(\frac{x_{i}-x}{h}) \; where \; K(u) = 1_{A}(u),\; A=\{u \mid \exists \, n \, s.t. \|u_{n}\|\leq \frac{h}{2}\}$$ 가 되겠다. 또 다른 kernel function으로는 Gaussian kernel이 있으며, 논문에서는 Guassian kernel을 고려한다. 이유는 그냥 식이 간단해져서.

## Denoising Autoencoder
"Extracting and composing robust features with denoising autoencoders"라는 2008년 논문에서 처음으로 제시된 Denoising autoencoder는 되게 간단한 구조이다.
1. Training input $x$를 그냥 넣지 않고, Gaussian noise를 추가한, $\widetilde{x}=x+\varepsilon, \; \varepsilon \sim N(0,\sigma^{2}I)$를 encoder의 input으로 준다.
2. Encoder, Decoder를 통과하고 나온 output $x_{out}$을 기존 Autoencoder 처럼 Reconstruction error, L2 loss로 학습한다. 다만, $\widetilde{x}$가 아닌 $x$와 비교한다는 것.

어떻게 보면 VAE와 매우 유사하지만 latent 단이 아니라 input 단에서 noise를 넣고 있다. 또 어떻게 보면 2015년 처음으로 제시된 Diffusion Model과 "input에 noise를 넣고, 모델을 통과했을 때 기존 input과의 차이를 본다"는 점에서 비슷하지만, input에 noise를 여러 step에 걸쳐 계속 넣는 방향으로 발전한 것이라 볼 수 있겠다.

## 개선점
Main idea는 Score Matching Principle과 Denoising Autoencoder approach를 합치는 것이다.

## Summary

# 3. NCSN
*[Yang Song Blog](https://yang-song.net/blog/2021/score/) 논문 저자의 Blog에 본인이 정리해둔 글이 있다! 직접 보고 많은 도움이 되었다.*

## 기존 Denoising Score-Matching의 문제점
우리의 원래 목적은 original data distribution $p_{data}(x)$를 score를 통해 유추하는 것인데, 해당 방법은 true data distribution의 score가 아니라 joint density $p_{\sigma}(\widetilde{x} \mid x)p_{data}(x)$의 score와의 matching이기에 원래 목적과 멀어진다.

## 개선점
Main idea는

# 4. NCSNv2

# 5. SDE

# Reference

## Websites

[사이트 출처 1] (https://www.youtube.com/watch?v=KzrdkZUrbPk)

## Papers

[1] Hyvärinen, A., & Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research, 6(4).

[2] Vincent, P. (2011). A connection between score matching and denoising autoencoders. Neural computation, 23(7), 1661-1674.

[3] Song, Y., & Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32.

[4] Song, Y., & Ermon, S. (2020). Improved techniques for training score-based generative models. Advances in neural information processing systems, 33, 12438-12448.

[5] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.

[6] Welling, M., & Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of the 28th international conference on machine learning (ICML-11) (pp. 681-688).

[7] Du, Y., & Mordatch, I. (2019). Implicit generation and modeling with energy based models. Advances in Neural Information Processing Systems, 32.

