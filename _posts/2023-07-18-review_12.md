---
layout: single
title:  "[Review] Diffusion Transformer (DiT)"
categories: review
tag: [review, Generative Model]
author_profile: false
---

Diffusion Model의 기본 Architecture는 DDPM 때 부터 U-Net을 주로 써왔다. 그러나, "굳이 U-Net?"이라는 의문이 들 수 있기에. Transformer를 사용한 Diffusion Transformer, DiT 논문을 살펴보자. 정확한 논문 이름은 Scalable Diffusion Models with Transformers.

# 1. Introduction

## Transformer & ViT

[[My Transformer Review]](https://gyoukchu.github.io/review/review_1/#3-model-architecture)

Vision Transformer(ViT)에 대한 내용을 아직 글을 작성하지는 않았지만, 워낙에 유명하기도 하고 Transformer 구조와 크게 다른 것이 없기에. 일단 큰 틀은 아래 사진과 같다.

![ViT]({{site.url}}/images/review/DiT/1.png)

논문 제목처럼 Image를 PxP patch로 나눈 뒤 이 각각의 patch를 Transformer에서 하나의 단어로 취급하는 구조이다. Position Embedding도 Transformer에서 각 단어가 문장에서 몇 번째 위치인지에 대한 정보를 담고 있듯이 ViT에서는 각 patch가 image의 어떤 위치에 있었는지에 대한 정보를 담고 있고, 학습해도 되고 sinusoidal embedding으로 encoding해도 된다. BERT에서 idea를 가져와서 BERT에서의 CLS 토큰 처럼 추가로 학습할 0번 토큰을 넣어주고 있다.

ViT 모델 구조에서 hyperparameter로는 Transformer Encoder Layer 개수, Hidden dimension size, Attention 시 head 수, MLP size에 따라 Base, Large, Huge 모델로 나뉜다.

## DM / LDM



## Classifier Free Guidance

## Architecture Complexity vs Gflops

# 2. Design

## Patchify

![Patchify]({{site.url}}/images/review/DiT/2.png)

## Block design

![DiTBlock]({{site.url}}/images/review/DiT/3.png)

## Model size

![DiT Size]({{site.url}}/images/review/DiT/4.png)

# 3. Experiment Results

![DiT Result]({{site.url}}/images/review/DiT/5.png)

## Ablation Studies

![DiT Ablation 1/2]({{site.url}}/images/review/DiT/6.png)

![DiT Ablation 3/4]({{site.url}}/images/review/DiT/7.png)

# Summary

# Reference

## Websites

[사이트 출처 1] 

## Papers

[1] Peebles, W., & Xie, S. (2022). Scalable diffusion models with transformers. arXiv preprint arXiv:2212.09748.

[2] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.