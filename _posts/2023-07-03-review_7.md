---
layout: single
title:  "[Review] SDE"
categories: review
tag: [review, Generative Model]
author_profile: false
---

앞서 Review한 Diffusion Model과, score-based model을 모두 통합하는 generalized framework를 제시한, Score-Based Generative Modeling through Stochastic Differential Equations (SDE) 논문을 살펴보자. *이것도 Yang Song 씨의 논문이다.*

# 1. Introduction
Training data에 점차 증가하는 noise를 주입하면서 corrupting한 뒤, reverse process를 통해 이 corrupting process를 학습하는 생성 모델은 2가지가 있다.

## SMLD
[[My NCSN Review]](https://gyoukchu.github.io/review/review_3/#3-ncsn)

여기서 SMLD는 Denoising Score Matching with Langevin Dynamics의 줄임말로, NCSN이랑 동일한 것이다. $\sigma_{i}$가 $\frac{\sigma_{1}}{\sigma_{2}}=...=\frac{\sigma_{L-1}}{\sigma_{N}}<1$를 만족하는 noise들이라고 하자. 그리고 $$p_{\sigma}(\widetilde{x} \mid x):=N(\widetilde{x} ; x, \sigma^{2}I)$$일 때 $$p_{\sigma}(x):=\int p_{data}(t)p_{\sigma}(x \mid t)dt$$로 주어지는 perturbed data distribution를 고려하자. 이 때, NCSN에서 다루었듯이 충분히 작은 noise level인 $\sigma_{1}:=\sigma_{min}$에 대해서는 $p_{\sigma_{min}}(x)\sim p_{data}(x)$ 이면서도 충분히 큰 noise level인 $\sigma_{N}:=\sigma_{max}$에 대해서는 $p_{\sigma_{max}}(x)\sim N(0,\sigma_{max}^{2}I)$를 만족한다. 그랬을 때 NCSN model은 denoising score matching의 weighted sum으로 하나의 score-based model을 학습한다. 즉, $$\theta^{*}:=\underset{\theta}{arg\,min\,}\sum_{i=1}^{N} \sigma_{i}^{2}E_{p_{data}}E_{p_{\sigma_{i}}(\widetilde{x} \mid x)}[\|s_{\theta}(\widetilde{x},\sigma_{i})-\nabla_{\widetilde{x}}log\,p_{\sigma_{i}}(\widetilde{x} \mid x)\|_{2}^2] \; \\ where\;\; \nabla_{\widetilde{x}}log\,p_{\sigma_{i}}(\widetilde{x} \mid x)=-\frac{\widetilde{x}-x}{\sigma_{i}^{2}}\;, p_{\sigma_{i}}(\widetilde{x} \mid x)\sim N(x,\sigma_{i}^{2}I)$$

그리고 Inference 시에는 M-step Langevin MCMC를 통해 각 noise level에서 sample을 얻는다. $$\widetilde{x}_{i}^{m}=\widetilde{x}_{i-1}^{m}+\frac{\epsilon_{i}}{2}s_{\theta^{*}}(\widetilde{x}_{i-1}^{m},\sigma_{i})+\sqrt{\epsilon_{i}}z_{i}^{m} \\ where\;z_{i}^{m}\sim N(0,I), m=1,2,...,M, i=N,N-1,...,1 \\ x_{N}^{0}\sim N(x\mid 0,\sigma_{max}^{2}I),\; x_{i}^{0}=x_{i+1}^{M}\;\forall i<N$$

## DDPM
[[My DDPM Review]](https://gyoukchu.github.io/review/review_2/#3-ddpm)

$\beta_{t}:10^{-4}\searrow 0.02$인 noise level에 대해서, training data $x_{0}\sim p_{data}(x)$에 대해 discrete Markov chain $\{x_{0},...,x_{N}\}$을 다음과 같이 구성한다: $$p(x_{i}\mid x_{i-1})=N(x_{i};\sqrt{1-\beta _{i}}X_{i-1}, \beta _{i}I)$$. 한 방에 적으면, $$p_{\alpha_{i}}(x_{i}\mid x_{0})=N(x_{i};\sqrt{\alpha_{i}}x_{0},(1-\alpha_{i})I)\;where\;\alpha_{i}=\prod_{j=1}^{i}(1-\beta_{j})$$. 마찬가지로 $$p_{\alpha_{i}}(x):=\int p_{data}(t)p_{\alpha_{i}}(x \mid t)dt$$ 로 주어지는 perturbed data distribution를 고려할 때, reverse process distribution을 parametrize한 $$p_{\theta}(x_{i-1}\mid x_{i})=N(x_{i-1};\frac{1}{\sqrt{1-\beta_{i}}}(x_{i}+\beta_{i}s_{\theta}(x_{i},i)),\beta_{i}I)$$를 학습한다. 이 때, $$s_{\theta}(x_{i},i)$$는 noisy input 분포 $$p_{\alpha_{i}}(x)$$의 score와 matching하여 학습한다. 즉, $$\theta^{*}:=\underset{\theta}{arg\,min\,}\sum_{i=1}^{N} (1-\alpha_{i})E_{p_{data}}E_{p_{\alpha_{i}}(\widetilde{x} \mid x)}[\|s_{\theta}(\widetilde{x},i)-\nabla_{\widetilde{x}}log\,p_{\alpha_{i}}(\widetilde{x} \mid x)\|_{2}^2] \; \\ where\;\; p_{\alpha_{i}}(\widetilde{x} \mid x)\sim N(\sqrt{\alpha_{i}}x,(1-\alpha_{i})I)$$

그리고 inference 시에는 reverse Markov chain을 따라 Gaussian noise로부터 sample을 얻는다. $$x_{i-1}=\frac{1}{\sqrt{1-\beta_{i}}}(x_{i}+\beta_{i}s_{\theta^{*}}(x_{i},i))+\sqrt{\beta_{i}}z_{i} \\ where\;\; x_{N},z_{i}\sim N(0,I)\,\forall i,\;i=N,N-1,...,1$$ 참고로 논문에서 저자는 이 sampling 방법을 "ancestral sampling"이라고 부르고 있다.

참고해야 될 부분은 두 모델 모두 optimal model $s_{\theta^{*}}(x_{i},i)$를 perturbed data distribution의 score(gradient of log-likelihood)와 matching 하고 있으며, 여러 noise level에 대한 score matching 간의 weighted sum으로 학습하고 있다. 이 때, coefficient는 NCSN에서는 $\sigma_{i}^{2}$, DDPM에서는 $1-\alpha_{i}$인데 두 상수 모두 각각의 noise level $i$에 대해서 $\frac{1}{E[\|\nabla_{\widetilde{x}}log\,p_{i}(\widetilde{x} \mid x)\|_{2}^2]}$에 비례하도록 하여 weight를 통해 score matching term간 noise level에 따른 차이가 없도록 하였다. (NCSN은 실험적으로 결정한 것이고, DDPM은 수식에 따라 결정된 것이다.)

위에 있는 수식이 DDPM 논문에 있는 수식이랑 겉으로 보기에는 다른 것 처럼 보이지만, 사실 SMLD와 동일한 형태로 보일 수 있도록 저자가 편의를 위해 바꾼 것이다. 살펴보자면, DDPM의 forward distribution $$p_{\alpha_{i}}(x_{i}\mid x_{0})=N(x_{i};\sqrt{\alpha_{i}}x_{0},(1-\alpha_{i})I)$$를 우리는 Reparameterization trick을 이용하여, 다시 말해 Gaussian 분포에서 얻은 sample $$\epsilon$$을 variance에 곱한걸 평균에 더해서 $$x_{i}$$를 얻었었다: $$x_{i}=\sqrt{\alpha_{i}}x_{0}+\sqrt{1-\alpha_{i}}\epsilon_{i}\;where\;\epsilon_{i}\sim N(0,I)$$. 그랬을 때, 위 식에서 $$\nabla_{\widetilde{x}}log\,p_{\alpha_{i}}(\widetilde{x} \mid x)=-\,\frac{\widetilde{x}-\sqrt{\alpha_{i}}x_{0}}{1-\alpha_{i}}=-\,\frac{\epsilon_{i}}{\sqrt{1-\alpha_{i}}}$$가 되는 걸 알 수 있다. 기존에 DDPM에서 서술했던 방식의 Loss term은 $$E_{N, x_{0}, \epsilon}[\|\epsilon_{\theta}(\widetilde{x},i)-\epsilon\|_{2}^2]$$로, noise를 학습하는 network라고 봤지만 사실 $$s_{\theta}(\widetilde{x},i):=-\,\frac{\epsilon_{\theta}(\widetilde{x},i)}{\sqrt{1-\alpha_{i}}}$$로 본다면 $$\alpha_{i}$$는 상수이기 때문에 $$\epsilon_{\theta}(\widetilde{x},i)$$를 학습하는 것과 $$s_{\theta}(\widetilde{x},i)$$를 학습하는 건 똑같은 말이 된다. 따라서, $$\sum_{i=1}^{N} (1-\alpha_{i})E_{p_{data}}E_{p_{\alpha_{i}}(\widetilde{x} \mid x)}[\|s_{\theta}(\widetilde{x},i)-\nabla_{\widetilde{x}}log\,p_{\alpha_{i}}(\widetilde{x} \mid x)\|_{2}^2]=E_{N, x_{0}, \epsilon}[\|\epsilon_{\theta}(\widetilde{x},i)-\epsilon\|_{2}^2]$$ 임을 알 수 있다.

## SDE
[[SDE란]](https://gyoukchu.github.io/review/review_6/#sde%EB%9E%80)

SDE는 Stochastic process의 Differential Equation으로, $$dX(t)=f(t,X(t))dt+g(t,X(t))dW(t)\;,X(0)=X_{0}$$의 형태이다. 혹은, $$X(T)=X_{0}+\int_{0}^{T}f(s,X(s))dx + \int_{0}^{T}g(x,X(s))dW(s)$$의 형태이다. 이 때 두 번째 적분 term은 integrand/integrator 모두 Stochastic process인 Itô integral인데, 정확히는 모르겠지만 Riemann-Stieltjes 적분이랑 비슷하게 정의된다고 한다. (확실한 건 $$\int_{0}^{T}GdW(s)=\int_{0}^{T}GW'ds$$는 Brownian motion W가 미분 불가능하므로, 이렇게 단순하게 풀리는 적분은 아니다.) 적분식으로 나타낸 이유는, SDE의 해를 위와 같은 적분 형태로 수치적으로 구하는 SDE integrator가 Euler-Maruyama, Runge-Kutta, Leimkuhler-Matthews 등 다양한 방법이 이미 알려져있기 때문이다. 그리고 위와 같은 SDE가, drift term f와 diffusion term g가 globally Lipscitz하면 unique strong solution을 가진다고 알려져있다.

또한, network의 forward pass나 backpropagation을 ODE/SDE Solver를 이용하는 ODE-Net과 같은 방식이 제안되었었다.

# 2. Score-Based Generative Modeling with SDEs

![SDE]({{site.url}}/images/review/SDE/2.png)

## Forward SDE

우선 저자가 SDE를 떠올리게 된 이유는, DDPM에서의 discrete Markov chain을 contiuous Markov chain으로 일반화해보는 시도에서 이런 아이디어가 나왔을 것이다. DDPM에서의 discrete time variable $i$가 아닌, continuous time variable $t\in [0,T]$를 고려한 diffusion process $\mathbf{x}(t)$를 고려한다. 이 때 $\mathbf{x}(0)$는 실제 데이터 분포 $p_{0}$의 i.i.d. sample이고, $\mathbf{x}(T)\sim p_{T}$, $p_{T}$는 Gaussian distribution와 같은 prior distribution이다. 

그래서 이 diffusion process는 위에서 말한 Itô SDE의 solution으로 모델링할 수 있다. $$d\mathbf{x}=\mathbf{f}(\mathbf{x},t)dt+g(t)d\mathbf{w}$$ 논문에서 활용한 SDE인데, diffusion coefficient를 stochastic process에 independent하고 matrix가 아닌 scalar function으로 가정하고 있다. $$\mathbf{x}(t)$$의 pdf를 $$p_{t}(\mathbf{x})$$라 하고, $$s<t$$일 때 $$\mathbf{x}(s)$$에서 $$\mathbf{x}(t)$$로의 transition kernel을 $$p_{st}(\mathbf{x}(t)\mid \mathbf{x}(s))$$로 한다.

## Reverse SDE
prior distribution $p_{T}$로 부터 얻은 sample들 $\mathbf{x}(T)$로 부터 실제 데이터 분포에서의 sample $\mathbf{x}(0)$를 생성해낼 수 있는데, 위 diffusion process의 reverse 또한 마찬가지로 diffusion process이며 다음과 같은 SDE로 표현된다고 한다. $$d\mathbf{x}=[\mathbf{f}(\mathbf{x},t)-g(t)^{2}\nabla_{\mathbf{x}}log\;p_{t}(\mathbf{x})]dt+g(t)d\overline{\mathbf{w}}$$ [[(Anderson, 1982)-Section 5 참고]](https://www.sciencedirect.com/science/article/pii/0304414982900515) 이 때, dt는 T에서 0으로 감소하는 negative timestep이고, $$\overline{\mathbf{w}}$$는 Wiener process이지만 time이 T에서 0으로 감소하는 방향. 따라서, $$p_{t}(\mathbf{x})$$의 score를 알면 sampling을 할 수 있게 된다.

그래서 NCSN이나 DDPM과 동일하게 score-matching을 기반으로 분포를 학습한다.

$$\theta^{*}:=\underset{\theta}{arg\,min\,}\mathbb{E}_{t}\Big\{\lambda(t) \mathbb{E}_{\mathbf{x}(0)}E_{\mathbf{x}(t) \mid \mathbf{x}(0)}[\|s_{\theta}(\mathbf{x}(t),t)-\nabla_{\mathbf{x}(t)}log\,p_{0t}(\mathbf{x}(t) \mid \mathbf{x}(0))\|_{2}^2]\Big\} \\ where\;\; \lambda:[0,T]\rightarrow \mathbb{R}_{>0}, t\sim Unif[0,T], \mathbf{x}(0)\sim p_{0}(\mathbf{x}), \mathbf{x}(t)\sim p_{0t}(\mathbf{x}(t)\mid \mathbf{x}(0))$$

여기서 $$\lambda(t)$$는 weight function으로, 마찬가지로 NCSN과 DDPM과 똑같이 $$\lambda(t)\propto \frac{1}{\mathbb{E}[\|\nabla_{\mathbf{x}(t)}log\,p_{0t}(\mathbf{x}(t) \mid \mathbf{x}(0))\|_{2}^2]}$$를 만족하도록 설정한다. 그리고 논문에서 위 score matching은 denoising score matching 방식이지만, sliced score matching와 같은 다른 방식도 적용할 수 있다고 말하고 있다.

결국 저 transition kernel $$p_{0t}(\mathbf{x}(t)\mid \mathbf{x}(0))$$를 알아야 되는데, drift coefficient $$\mathbf{f}(\mathbf{x},t)$$가 affine일 때 transition kernel은 항상 Gaussian distribution이고 평균과 분산에 대한 식이 explicit하게 알려져있다고 한다. [[Section 5-2~5.5 참고]](https://users.aalto.fi/~asolin/sde-book/sde-book.pdf) 만약 affine 하지 않다면 Kolmogorov's forward equation을 풀거나 ~~라는데 이건 잘 모르겠고~~ denoising score matching이 아닌 sliced score matching 방식을 채택해서 해당 transition kernel의 score를 구하지 않는 방법으로 우회할 수 있다.

## VE, VP, sub-VP SDE

# 3. Solving the reverse SDE

## Reverse Diffusion Samplers

## PC Samplers

## Probability flow ODE

## Architecture

# 4. Controllable Generation

# 5. Summary

![SDE Summary]({{site.url}}/images/review/SDE/1.png)
Forward SDE: $$d\mathbf{x}=\mathbf{f}(\mathbf{x},t)dt+g(t)d\mathbf{w}$$

Reverse SDE: $$d\mathbf{x}=[\mathbf{f}(\mathbf{x},t)-g(t)^{2}\nabla_{\mathbf{x}}log\;p_{t}(\mathbf{x})]dt+g(t)d\overline{\mathbf{w}}$$

Corresponding Reverse ODE: $$dx=[f(x,t)-(1/2)g(t)^{2}\nabla_{x}log\;p_{t}(x)]dt$$

기존의 Diffusion model은 computationally expensive한 ancestral sampling 방식으로 reverse DE를 풀어서 데이터를 생성해냈으나, 본 논문에서는 reverse SDE/ODE를 기존의 numerical integrator를 통해 풂으로써 sampling을 하는 방법, 그리고 PC sampler나 deterministic sampler 등을 제시해 더 빠른 sampling을 할 수 있도록 하였다. 이후 더 좋은 reverse SDE/ODE integrator는 무엇인가에 대한 연구들이 이어지게 된다. [Zhang & Chen, 2022](https://arxiv.org/abs/2204.13902) [Lu et al., 2022](https://arxiv.org/abs/2206.00927)

# Reference

## Websites

[사이트 출처 1]

## Papers

[1] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.
